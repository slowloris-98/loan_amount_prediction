{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-X6QC24EKSd",
        "outputId": "3c67121b-f6f1-48e6-f994-533000391b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in ./miniconda3/envs/tensorflow/lib/python3.9/site-packages (0.3.4)\r\n",
            "Requirement already satisfied: packaging in ./miniconda3/envs/tensorflow/lib/python3.9/site-packages (from kagglehub) (24.1)\r\n",
            "Requirement already satisfied: requests in ./miniconda3/envs/tensorflow/lib/python3.9/site-packages (from kagglehub) (2.32.3)\r\n",
            "Requirement already satisfied: tqdm in ./miniconda3/envs/tensorflow/lib/python3.9/site-packages (from kagglehub) (4.67.0)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/envs/tensorflow/lib/python3.9/site-packages (from requests->kagglehub) (3.4.0)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/envs/tensorflow/lib/python3.9/site-packages (from requests->kagglehub) (3.10)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/envs/tensorflow/lib/python3.9/site-packages (from requests->kagglehub) (2.2.3)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/envs/tensorflow/lib/python3.9/site-packages (from requests->kagglehub) (2024.8.30)\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nRty1VmFENPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "# customer_path = os.path.join(path, \"customer.csv\")\n",
        "# loan_path = os.path.join(path, \"loan.csv\")\n",
        "\n",
        "# customer = pd.read_csv(customer_path)\n",
        "# loan = pd.read_csv(loan_path)\n",
        "# df = pd.merge(customer, loan, on='customer_id', how='inner').drop(\"loan_amount\", axis=1)\n",
        "df =pd.read_csv(\"/home/chun/Downloads/cs-267/project/join_df.csv\")"
      ],
      "metadata": {
        "id": "vtAZyzZsHc94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E7oxaBQBx4R"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Assuming the dataframe `df` is already loaded and contains 'funded_amount' as the target\n",
        "# Preprocess the dataset\n",
        "df = df.dropna()  # Handle missing data\n",
        "df = pd.get_dummies(df, drop_first=True)  # Convert categorical columns to one-hot encoding\n",
        "\n",
        "# Feature and target split\n",
        "X = df.drop('funded_amount', axis=1).values  # Features\n",
        "y = df['funded_amount'].values  # Target\n",
        "\n",
        "# Reshape data for RNN (adding a time-step dimension)\n",
        "# Assuming each sample is treated as a single time-step sequence\n",
        "X = np.expand_dims(X, axis=1)  # Shape: (samples, time-steps, features)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
        "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGI0SJ1DQiDR",
        "outputId": "8d97c9dd-785e-4f8a-859a-377de5232e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6545"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse_loss(y_true, y_pred):\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Build the RNN model\n",
        "model = Sequential([\n",
        "    LSTM(50, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.3),\n",
        "    LSTM(25, activation='tanh', return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(12, activation='relu'),\n",
        "    Dense(1)  # Single output neuron for regression\n",
        "])\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss=rmse_loss, metrics=['mae'])  # Use MSE loss for regression\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Mean Absolute Error: {test_mae:.2f}\")\n",
        "\n",
        "# Predict and analyze results\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Predicted loan amounts (first 5): {y_pred[:5].flatten()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qp-s3lte9kz",
        "outputId": "cd3b5e74-4f4f-4472-cb27-c91b3d294010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/chun/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 18150.6309 - mae: 15535.3115 - val_loss: 18528.1855 - val_mae: 15924.1387\n",
            "Epoch 2/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17990.1895 - mae: 15428.2383 - val_loss: 18426.9180 - val_mae: 15806.2666\n",
            "Epoch 3/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17969.2578 - mae: 15330.3145 - val_loss: 18280.6172 - val_mae: 15635.5449\n",
            "Epoch 4/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17918.8770 - mae: 15268.1729 - val_loss: 18091.0996 - val_mae: 15413.6494\n",
            "Epoch 5/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17562.3691 - mae: 14864.0762 - val_loss: 17861.8594 - val_mae: 15144.0566\n",
            "Epoch 6/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17136.2207 - mae: 14454.5713 - val_loss: 17595.1016 - val_mae: 14830.5400\n",
            "Epoch 7/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17003.6484 - mae: 14318.4121 - val_loss: 17295.4277 - val_mae: 14478.6885\n",
            "Epoch 8/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16866.1855 - mae: 14027.2275 - val_loss: 16966.6211 - val_mae: 14092.9648\n",
            "Epoch 9/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16290.0283 - mae: 13430.4482 - val_loss: 16610.6875 - val_mae: 13679.2012\n",
            "Epoch 10/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16032.9873 - mae: 13108.3691 - val_loss: 16230.7812 - val_mae: 13239.5742\n",
            "Epoch 11/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15701.0527 - mae: 12664.4746 - val_loss: 15830.4121 - val_mae: 12781.3477\n",
            "Epoch 12/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15155.4648 - mae: 12064.3623 - val_loss: 15412.9766 - val_mae: 12309.4990\n",
            "Epoch 13/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 14799.1826 - mae: 11739.2139 - val_loss: 14981.9766 - val_mae: 11831.9658\n",
            "Epoch 14/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 14496.6738 - mae: 11307.8145 - val_loss: 14540.5342 - val_mae: 11350.6797\n",
            "Epoch 15/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13673.8506 - mae: 10590.8926 - val_loss: 14092.2559 - val_mae: 10902.6729\n",
            "Epoch 16/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13441.0986 - mae: 10265.7148 - val_loss: 13641.0996 - val_mae: 10465.0859\n",
            "Epoch 17/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13101.9453 - mae: 9944.9922 - val_loss: 13194.9121 - val_mae: 10055.7266\n",
            "Epoch 18/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12551.6084 - mae: 9445.1289 - val_loss: 12753.7881 - val_mae: 9662.5449\n",
            "Epoch 19/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12453.0605 - mae: 9304.9766 - val_loss: 12326.3809 - val_mae: 9292.9365\n",
            "Epoch 20/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12071.0840 - mae: 8993.7012 - val_loss: 11918.5156 - val_mae: 8969.2949\n",
            "Epoch 21/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11410.7246 - mae: 8432.9463 - val_loss: 11533.7686 - val_mae: 8669.6816\n",
            "Epoch 22/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11069.3076 - mae: 8236.5498 - val_loss: 11176.7998 - val_mae: 8402.1484\n",
            "Epoch 23/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10716.4912 - mae: 7977.0327 - val_loss: 10860.6738 - val_mae: 8229.4697\n",
            "Epoch 24/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10609.3008 - mae: 7967.7148 - val_loss: 10581.3613 - val_mae: 8082.8013\n",
            "Epoch 25/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10324.6719 - mae: 7760.2358 - val_loss: 10343.0859 - val_mae: 7957.2861\n",
            "Epoch 26/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9960.7246 - mae: 7626.8335 - val_loss: 10145.0273 - val_mae: 7893.6274\n",
            "Epoch 27/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9945.4072 - mae: 7688.4360 - val_loss: 9991.8164 - val_mae: 7853.5942\n",
            "Epoch 28/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9823.9238 - mae: 7652.3291 - val_loss: 9871.3115 - val_mae: 7828.7695\n",
            "Epoch 29/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9803.9404 - mae: 7748.2603 - val_loss: 9780.5459 - val_mae: 7809.9165\n",
            "Epoch 30/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9678.6670 - mae: 7664.4824 - val_loss: 9717.8936 - val_mae: 7797.7900\n",
            "Epoch 31/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9516.2920 - mae: 7600.3950 - val_loss: 9674.1045 - val_mae: 7792.5029\n",
            "Epoch 32/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9551.8291 - mae: 7658.7856 - val_loss: 9643.7734 - val_mae: 7791.2954\n",
            "Epoch 33/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9587.6982 - mae: 7766.6328 - val_loss: 9624.9053 - val_mae: 7791.1421\n",
            "Epoch 34/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9633.0166 - mae: 7835.0488 - val_loss: 9610.8809 - val_mae: 7791.0522\n",
            "Epoch 35/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9535.8770 - mae: 7752.4517 - val_loss: 9601.1992 - val_mae: 7791.1543\n",
            "Epoch 36/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9704.0430 - mae: 7896.7178 - val_loss: 9596.0508 - val_mae: 7793.5811\n",
            "Epoch 37/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9534.2168 - mae: 7738.6772 - val_loss: 9593.2998 - val_mae: 7797.1118\n",
            "Epoch 38/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9523.5713 - mae: 7743.5239 - val_loss: 9590.2734 - val_mae: 7801.1743\n",
            "Epoch 39/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9620.5273 - mae: 7861.4946 - val_loss: 9587.5479 - val_mae: 7805.0137\n",
            "Epoch 40/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9630.1660 - mae: 7814.8887 - val_loss: 9586.3496 - val_mae: 7806.7778\n",
            "Epoch 41/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9597.5195 - mae: 7786.4492 - val_loss: 9588.1953 - val_mae: 7804.0840\n",
            "Epoch 42/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9472.2334 - mae: 7713.0381 - val_loss: 9586.5596 - val_mae: 7806.4619\n",
            "Epoch 43/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9701.4805 - mae: 7876.4370 - val_loss: 9584.4365 - val_mae: 7809.6997\n",
            "Epoch 44/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9538.7695 - mae: 7753.1108 - val_loss: 9585.8076 - val_mae: 7807.5898\n",
            "Epoch 45/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9608.9082 - mae: 7832.3530 - val_loss: 9584.5693 - val_mae: 7809.4927\n",
            "Epoch 46/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9719.4854 - mae: 7891.9668 - val_loss: 9585.5137 - val_mae: 7808.0317\n",
            "Epoch 47/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9535.2783 - mae: 7793.4912 - val_loss: 9586.4629 - val_mae: 7806.6079\n",
            "Epoch 48/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9692.7891 - mae: 7924.6343 - val_loss: 9585.9199 - val_mae: 7807.4204\n",
            "Epoch 49/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9530.6738 - mae: 7787.0576 - val_loss: 9587.5049 - val_mae: 7805.0757\n",
            "Epoch 50/50\n",
            "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9651.5967 - mae: 7860.3564 - val_loss: 9586.1094 - val_mae: 7807.1304\n",
            "Test Mean Absolute Error: 7807.13\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Predicted loan amounts (first 5): [15146.022 15146.022 15146.022 15146.022 15146.022]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "SvB-MzqeJP2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YgAfiLD2A4jt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}